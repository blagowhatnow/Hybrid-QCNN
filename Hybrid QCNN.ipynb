{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2b825f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adapted from https://github.com/AishSweety/hybrid-quantum-classical-models-for-image-classification\n",
    "#Might need revision.\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2961303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Define the transformation to resize the images to 224x224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resizing to 224x224\n",
    "    ToTensor()  # Convert the image to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-10 dataset with the transformation\n",
    "train_data = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,  # Apply the transform\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transform  # Apply the transform\n",
    ")\n",
    "\n",
    "# Create DataLoader for the training and test set\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce05ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pennylane as qml\n",
    "\n",
    "# Define the quantum circuit using PennyLane\n",
    "n_qubits = 5\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "# Define the QLayer\n",
    "n_layers = 3\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Quantum layers\n",
    "        self.qlayer1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer3 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "        self.qlayer4 = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 120)  # Adjust input size based on convolution output\n",
    "        self.fc2 = nn.Linear(120, 20)\n",
    "        self.fc3 = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = torch.flatten(x, start_dim=1)  # Flatten while preserving the batch dimension\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Quantum layer: Split into chunks for quantum layers\n",
    "        x_1, x_2, x_3, x_4 = torch.split(x, 5, dim=1)\n",
    "        x_1 = self.qlayer1(x_1)\n",
    "        x_2 = self.qlayer2(x_2)\n",
    "        x_3 = self.qlayer3(x_3)\n",
    "        x_4 = self.qlayer4(x_4)\n",
    "\n",
    "        # Concatenate and final fully connected layer\n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785303a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, 2024-09-30 20:44:50.595380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "dataset  = train_data\n",
    "\n",
    "# Initialize your CNN model\n",
    "cnn = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)  # Stochastic Gradient Descent optimizer\n",
    "# Split your data into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "#val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    ct = datetime.datetime.now()\n",
    "    print(f\"{epoch=}, {ct}\")\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients to avoid accumulation\n",
    "        outputs = cnn(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the model parameters\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844dee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# Set the model to evaluation mode\n",
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
