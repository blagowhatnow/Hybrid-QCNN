{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2b825f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adapted from https://github.com/AishSweety/hybrid-quantum-classical-models-for-image-classification\n",
    "#Might need revision.\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2961303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 170498071/170498071 [00:31<00:00, 5497199.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Define the transformation to resize the images to 224x224\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resizing to 224x224\n",
    "    ToTensor()  # Convert the image to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Download and load CIFAR-10 dataset with the transformation\n",
    "train_data = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transform,  # Apply the transform\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transform  # Apply the transform\n",
    ")\n",
    "\n",
    "# Create DataLoader for the training and test set\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce05ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pennylane as qml\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the quantum circuit using PennyLane\n",
    "n_qubits = 5\n",
    "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def qnode(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "# Define the QLayer\n",
    "n_layers = 3\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Fully connected layers before quantum layers\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 5)  # Output size must match quantum layer input size (5)\n",
    "\n",
    "        # Quantum layers\n",
    "        self.qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n",
    "\n",
    "        # Final fully connected layers\n",
    "        self.fc2 = nn.Linear(5, 10)  # Adjust input size to match quantum output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Flatten the tensor\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        # Fully connected layer (output size is now 5 to match quantum layer)\n",
    "        x = F.relu(self.fc1(x))\n",
    "\n",
    "        # Quantum layer\n",
    "        x = self.qlayer(x)\n",
    "\n",
    "        # Final fully connected layer\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785303a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, 2025-01-02 12:40:11.209813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "dataset  = train_data\n",
    "\n",
    "# Initialize your CNN model\n",
    "cnn = Net()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)  # Stochastic Gradient Descent optimizer\n",
    "# Split your data into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "#val_loader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    ct = datetime.datetime.now()\n",
    "    print(f\"{epoch=}, {ct}\")\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients to avoid accumulation\n",
    "        outputs = cnn(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update the model parameters\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "844dee81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# Set the model to evaluation mode\n",
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f'Accuracy on the validation set: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
